{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref. https://www.pyimagesearch.com/2017/02/13/recognizing-digits-with-opencv-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imutils.perspective import four_point_transform\n",
    "from imutils import contours\n",
    "import imutils\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.externals import joblib\n",
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imutils.perspective import four_point_transform\n",
    "from imutils import contours\n",
    "import imutils\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "data = pd.read_csv('HQ_quality.csv', sep=';', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run this function first\n",
    "def preprocess_and_find_display(image):\n",
    "    \n",
    "    image = imutils.resize(image.copy(), height=500)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,127,255,1)\n",
    "    a,cnts,h = cv2.findContours(thresh,1,2)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "    displayCnt = None\n",
    "\n",
    "    for cnt in cnts:\n",
    "        approx = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
    "        if len(approx)==4 and cv2.contourArea(approx) > 100*200 :\n",
    "            displayCnt = approx\n",
    "            #warped = four_point_transform(gray, approx.reshape(4, 2))\n",
    "            #plt.imshow(warped,cmap = 'gray')\n",
    "            #plt.show()\n",
    "            break\n",
    "            \n",
    "    # extract the thermostat display, apply a perspective transform\n",
    "    # to it\n",
    "    warped = four_point_transform(gray, displayCnt.reshape(4, 2))\n",
    "    output = four_point_transform(image, displayCnt.reshape(4, 2))\n",
    "    #plt.imshow(warped,cmap = 'gray')\n",
    "    #plt.show()\n",
    "    \n",
    "    return warped, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CROPPING\n",
    "def crop_image(screen):\n",
    "    image_width = screen.shape[1]\n",
    "    cropped_screen = screen[10:160, 10:(round((3/5)*image_width))]\n",
    "    return cropped_screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_image(cropped):\n",
    "    \n",
    "    h,width = cropped.shape\n",
    "    warped_1 = cropped[:, -round(width/4):]\n",
    "    warped_2 = cropped[:, -2*round(width/4):-round(width/4):]\n",
    "    warped_3 = cropped[:, -3*round(width/4):-2*round(width/4):]\n",
    "    warped_4 = cropped[:, :-3*round(width/4):]\n",
    "    result = [warped_4, warped_3, warped_2, warped_1]\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digits_loc(i, h_noise, h_2, lowThreshold, b, c, t, t_2):\n",
    "    \n",
    "    \n",
    "    image = cv2.imread('HQ_digital/' + data.loc[i, 'image'])\n",
    "    image_name = data.loc[i, 'image']\n",
    "    # pre-process the image\n",
    "    warped, output = preprocess_and_find_display(image)\n",
    "    \n",
    "    cropped = crop_image(warped)\n",
    "    separated_images = split_image(cropped)\n",
    "     \n",
    "    return (image_name, separated_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digits_clean_loc(i, h_noise, h_2, lowThreshold, b, c, t, t_2):\n",
    "    \n",
    "    \n",
    "    image = cv2.imread('HQ_digital/' + data.loc[i, 'image'])\n",
    "    image_name = data.loc[i, 'image']\n",
    "    # pre-process the image\n",
    "    warped, output = preprocess_and_find_display(image)\n",
    "    \n",
    "    #cropped = crop_image(warped)\n",
    "    #separated_images = split_image(cropped)\n",
    "    \n",
    "    digits = crop_digits(warped)\n",
    "    digits_clean, n = clean_digits(digits, th_pix_blanc_tot, th_pix_blanc_sup)\n",
    "    #pixels_test.append(digits_clean)\n",
    "    \n",
    "    return (image_name, digits_clean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_digits(image):\n",
    "    digits = []\n",
    "    image_width = image.shape[1]\n",
    "    cropped = image[10:160, 10:(round((3/5)*image_width))]\n",
    "    width = cropped.shape[1]\n",
    "    w_1 = cropped[:, -round(width/4):]\n",
    "    w_2 = cropped[:, -2*round(width/4):-round(width/4):]\n",
    "    w_3 = cropped[:, -3*round(width/4):-2*round(width/4):]\n",
    "    w_4 = cropped[:, :-3*round(width/4):]\n",
    "    digits.append(w_1)\n",
    "    digits.append(w_2)\n",
    "    digits.append(w_3)\n",
    "    digits.append(w_4)\n",
    "    return digits\n",
    "\n",
    "def suppress_black_contour(image, th_pix_blanc):\n",
    "    h, w = image.shape\n",
    "    nb_pix_rect = 0 # left crop\n",
    "    x = 0\n",
    "    while nb_pix_rect <th_pix_blanc:\n",
    "        left_rect = image[:,:x]\n",
    "        nb_pix_rect = np.sum(left_rect == 255)\n",
    "        x += 1\n",
    "    img = image[:, x +1 :]\n",
    "    nb_pix_rect = 0 # right crop\n",
    "    x = 0\n",
    "    while nb_pix_rect <th_pix_blanc:\n",
    "        right_rect = image[:,w-x:]\n",
    "        nb_pix_rect = np.sum(right_rect == 255)\n",
    "        x += 1\n",
    "    img = img[:, :w-x +1]\n",
    "    nb_pix_rect = 0  # top crop\n",
    "    x = 0\n",
    "    while nb_pix_rect <th_pix_blanc/3:\n",
    "        top_rect = image[h-x +1:,:]\n",
    "        nb_pix_rect = np.sum(top_rect == 255)\n",
    "        x += 1\n",
    "    img = img[:h-x, :]\n",
    "    nb_pix_rect = 0 # bottom crop\n",
    "    x = 0\n",
    "    while nb_pix_rect <th_pix_blanc/3:\n",
    "        bot_rect = image[:x,:]\n",
    "        nb_pix_rect = np.sum(bot_rect == 255)\n",
    "        x += 1\n",
    "    img = img[x+1:, :]\n",
    "    return img\n",
    "\n",
    "def clean_digits(digits, th_pix_blanc_tot, th_pix_blanc_sup):\n",
    "    digits_clean = []\n",
    "    stop = 0\n",
    "    nb_digits = 0\n",
    "    for i in range(4):\n",
    "        image = digits[i]\n",
    "        #image = cv2.cvtColor(digits[i], cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.bilateralFilter(image, 10, 10, 100)\n",
    "        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 17, 2)\n",
    "        inv = cv2.bitwise_not(thresh)\n",
    "        kernel = np.ones((7,7), np.uint8)\n",
    "        closing = cv2.morphologyEx(inv, cv2.MORPH_CLOSE, kernel)\n",
    "        dilatation = cv2.dilate(closing, np.ones((3,3), np.uint8), iterations = 2)\n",
    "        plt.imshow(dilatation, cmap = \"gray\")\n",
    "        k = np.sum(dilatation == 255)\n",
    "        #print(k)\n",
    "        if k > th_pix_blanc_tot and stop == 0:\n",
    "            im2 = suppress_black_contour(dilatation, th_pix_blanc_sup)\n",
    "            h, w = im2.shape\n",
    "            if h> 80 and w >25: # pour ne pas garder les petits coins d'images tout blancs\n",
    "                im3 = cv2.resize(im2, (80,50)).flatten()\n",
    "                digits_clean.append(im3)\n",
    "                #plt.imshow(im2,cmap = \"gray\")\n",
    "                #plt.show()\n",
    "                nb_digits +=1\n",
    "            else:\n",
    "                stop = 1\n",
    "        digits_clean = digits_clean[::-1]\n",
    "    return digits_clean, nb_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### PARAMETERS TO CHOOSE #######\n",
    "i = 0\n",
    "h_noise = 10 # noise coefficient\n",
    "h_2 = 15\n",
    "lowThreshold = 50 # canny edge detection\n",
    "b = 200 # brightness\n",
    "c = 120  # contrast\n",
    "t = 150 # threshold to separate white/black\n",
    "t_2 = 150\n",
    "th_pix_blanc_tot = 150\n",
    "th_pix_blanc_sup = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_images = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    # print(i)\n",
    "    try:\n",
    "        list_images.append(digits_loc(i,10,15,50,200,120,150,150))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "len(list_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>arrays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e104664ba1792dde641d87cd5d95f1df06786140.jpg</td>\n",
       "      <td>[[[42, 42, 42, 42, 39, 39, 41, 40, 36, 36, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48990b5cbe173868040bd33f06fb1b80c2b4f28a.jpg</td>\n",
       "      <td>[[[35, 35, 35, 32, 30, 31, 32, 31, 32, 34, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9e111802446b62b86aeffe911415ad28227caba7.jpg</td>\n",
       "      <td>[[[34, 33, 34, 34, 34, 32, 33, 35, 35, 35, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f78fe5a461f28bc770a7dd856878bb4a314a9027.jpg</td>\n",
       "      <td>[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c836ea17748e562c99f93edc51f2b900664ec37d.jpg</td>\n",
       "      <td>[[[30, 32, 32, 32, 32, 27, 27, 32, 32, 31, 34,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image  \\\n",
       "0  e104664ba1792dde641d87cd5d95f1df06786140.jpg   \n",
       "1  48990b5cbe173868040bd33f06fb1b80c2b4f28a.jpg   \n",
       "2  9e111802446b62b86aeffe911415ad28227caba7.jpg   \n",
       "3  f78fe5a461f28bc770a7dd856878bb4a314a9027.jpg   \n",
       "4  c836ea17748e562c99f93edc51f2b900664ec37d.jpg   \n",
       "\n",
       "                                              arrays  \n",
       "0  [[[42, 42, 42, 42, 39, 39, 41, 40, 36, 36, 36,...  \n",
       "1  [[[35, 35, 35, 32, 30, 31, 32, 31, 32, 34, 36,...  \n",
       "2  [[[34, 33, 34, 34, 34, 32, 33, 35, 35, 35, 36,...  \n",
       "3  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "4  [[[30, 32, 32, 32, 32, 27, 27, 32, 32, 31, 34,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.DataFrame(list_images, columns = ['image', 'arrays'])\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>used_liter</th>\n",
       "      <th>image</th>\n",
       "      <th>used_liter2</th>\n",
       "      <th>arrays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>e104664ba1792dde641d87cd5d95f1df06786140.jpg</td>\n",
       "      <td>33</td>\n",
       "      <td>[[[42, 42, 42, 42, 39, 39, 41, 40, 36, 36, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>48990b5cbe173868040bd33f06fb1b80c2b4f28a.jpg</td>\n",
       "      <td>29</td>\n",
       "      <td>[[[35, 35, 35, 32, 30, 31, 32, 31, 32, 34, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230</td>\n",
       "      <td>9e111802446b62b86aeffe911415ad28227caba7.jpg</td>\n",
       "      <td>230</td>\n",
       "      <td>[[[34, 33, 34, 34, 34, 32, 33, 35, 35, 35, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>f78fe5a461f28bc770a7dd856878bb4a314a9027.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>238</td>\n",
       "      <td>c836ea17748e562c99f93edc51f2b900664ec37d.jpg</td>\n",
       "      <td>238</td>\n",
       "      <td>[[[30, 32, 32, 32, 32, 27, 27, 32, 32, 31, 34,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   used_liter                                         image used_liter2  \\\n",
       "0          33  e104664ba1792dde641d87cd5d95f1df06786140.jpg          33   \n",
       "1          29  48990b5cbe173868040bd33f06fb1b80c2b4f28a.jpg          29   \n",
       "2         230  9e111802446b62b86aeffe911415ad28227caba7.jpg         230   \n",
       "3          43  f78fe5a461f28bc770a7dd856878bb4a314a9027.jpg          43   \n",
       "4         238  c836ea17748e562c99f93edc51f2b900664ec37d.jpg         238   \n",
       "\n",
       "                                              arrays  \n",
       "0  [[[42, 42, 42, 42, 39, 39, 41, 40, 36, 36, 36,...  \n",
       "1  [[[35, 35, 35, 32, 30, 31, 32, 31, 32, 34, 36,...  \n",
       "2  [[[34, 33, 34, 34, 34, 32, 33, 35, 35, 35, 36,...  \n",
       "3  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "4  [[[30, 32, 32, 32, 32, 27, 27, 32, 32, 31, 34,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_labels(old_label):\n",
    "    number_str = str(old_label)\n",
    "    if len(number_str) == 1:\n",
    "        return '   ' + number_str\n",
    "    if len(number_str) == 2:\n",
    "        return '  ' + number_str\n",
    "    if len(number_str) == 3:\n",
    "        return ' ' + number_str\n",
    "    if len(number_str) == 4:\n",
    "        return number_str\n",
    "    \n",
    "#define new column for the labels, where each of the label is a string of length 4\n",
    "data['used_liter2'] = data['used_liter'].apply(lambda x: new_labels(x))\n",
    "full_data = pd.merge(data, new_data, on= 'image').copy()\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit_data = full_data[['used_liter2','arrays']]\n",
    "digit_label = [small_number for big_number in digit_data['used_liter2'] for small_number in big_number]\n",
    "digit_array = [array for list_of_arrays in digit_data['arrays'] for array in list_of_arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[[42, 42, 42, 42, 39, 39, 41, 40, 36, 36, 36, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>[[52, 52, 48, 49, 52, 51, 50, 50, 50, 51, 51, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[[46, 45, 45, 49, 50, 51, 51, 48, 47, 46, 48, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[40, 40, 40, 40, 40, 39, 36, 38, 38, 38, 40, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>[[35, 35, 35, 32, 30, 31, 32, 31, 32, 34, 36, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                              array\n",
       "0        [[42, 42, 42, 42, 39, 39, 41, 40, 36, 36, 36, ...\n",
       "1        [[52, 52, 48, 49, 52, 51, 50, 50, 50, 51, 51, ...\n",
       "2     3  [[46, 45, 45, 49, 50, 51, 51, 48, 47, 46, 48, ...\n",
       "3     3  [[40, 40, 40, 40, 40, 39, 36, 38, 38, 38, 40, ...\n",
       "4        [[35, 35, 35, 32, 30, 31, 32, 31, 32, 34, 36, ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_result = pd.DataFrame(\n",
    "    {'label': digit_label,\n",
    "     'array': digit_array\n",
    "    })\n",
    "\n",
    "digit_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIGITS_LOOKUP = {\n",
    "\t(1, 1, 1, 0, 1, 1, 1): 0,\n",
    "\t(0, 0, 1, 0, 0, 1, 0): 1,\n",
    "\t(1, 0, 1, 1, 1, 0, 1): 2,\n",
    "\t(1, 0, 1, 1, 0, 1, 1): 3,\n",
    "\t(0, 1, 1, 1, 0, 1, 0): 4,\n",
    "\t(1, 1, 0, 1, 0, 1, 1): 5,\n",
    "\t(1, 1, 0, 1, 1, 1, 1): 6,\n",
    "\t(1, 0, 1, 0, 0, 1, 0): 7,\n",
    "\t(1, 1, 1, 1, 1, 1, 1): 8,\n",
    "\t(1, 1, 1, 1, 0, 1, 1): 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def individual_prediction(roi, tresh_area):\n",
    "    w, h = (120,64)\n",
    "    (roiH, roiW) = roi.shape\n",
    "    (dW, dH) = (int(roiW * 0.25), int(roiH * 0.15))\n",
    "    dHC = int(roiH * 0.05)\n",
    "\n",
    "    # define the set of 7 segments\n",
    "    segments = [\n",
    "        ((0, 0), (w, dH)),\t# top\n",
    "        ((0, 0), (dW, h // 2)),\t# top-left\n",
    "        ((w - dW, 0), (w, h // 2)),\t# top-right\n",
    "        ((0, (h // 2) - dHC) , (w, (h // 2) + dHC)), # center\n",
    "        ((0, h // 2), (dW, h)),\t# bottom-left\n",
    "        ((w - dW, h // 2), (w, h)),\t# bottom-right\n",
    "        ((0, h - dH), (w, h))\t# bottom\n",
    "        ]\n",
    "    on_segments = [0] * len(segments)\n",
    "\n",
    "    # loop over the segments\n",
    "    for (i, ((xA, yA), (xB, yB))) in enumerate(segments):\n",
    "        # extract the segment ROI, count the total number of\n",
    "        # thresholded pixels in the segment, and then compute\n",
    "        # the area of the segment\n",
    "        segROI = roi[yA:yB, xA:xB]\n",
    "        # plt.imshow(segROI,cmap = \"gray\")\n",
    "        # plt.show()\n",
    "        total = cv2.countNonZero(segROI)\n",
    "        area = (xB - xA) * (yB - yA)\n",
    "\n",
    "        # if the total number of non-zero pixels is greater than\n",
    "        # 40% of the area, mark the segment as \"on\"\n",
    "        if total / float(area) > tresh_area:\n",
    "            on_segments[i]= 1\n",
    "    try:\n",
    "        digit = DIGITS_LOOKUP[tuple(on_segments)]\n",
    "    except KeyError:\n",
    "        digit = ''\n",
    "    \n",
    "    return digit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALcAAAD8CAYAAAA18TUwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_array = digit_result.array[19]\n",
    "cv2.imwrite('color_img.jpg', test_array)\n",
    "test_image = cv2.imread('color_img.jpg')\n",
    "\n",
    "#from IPython.display import Image\n",
    "#Image(\"color_img.jpg\")\n",
    "\n",
    "#test_image = cv2.resize(test_image, (test_image.shape[0], test_image.shape[0]))\n",
    "gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "inv_image = cv2.threshold(gray, 25, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "plt.imshow(inv_image, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_prediction(inv_image, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the image is not adequate for CV prediction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
